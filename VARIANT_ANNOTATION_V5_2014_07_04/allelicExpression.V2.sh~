##############################################################################################
###
###   CHANGE: 23/01/15 JChiron modification 
###   REASON:
###   - to use HGVS format annotation for c. and p. : --hgvs parameter added
###   - to extended splice site to 5b around exon 
###
###   WARNING:  CHANGE with respect to version in V3
###   REASON: 
###    - an important number of variants that were not annotated by ANNOVAR
###          due to scarse number of alternative alleles  ....
###    - ... but yet presenting the "correct" alt allele in the VCF file generated by samtools
###    - ... were reported with DP4=0,0,0,0 ...
###    - ... hence generating an important number of variants with NA information 
###   CHANGE:
###   In V4, the position is always reported with the observed nb of total REF and ALT alleles
###     even if the alt allelele reported in VCF is not "." but provided that it is the "correct" 
###     allele code
###
###   CHANGE:
###   Use of the new SAMTOOLS / BCFTOOLS GITHUB version 0.2.0
###   
###   look for WARNING !!!! WARNING !!!! lines below
###
##############################################################################################

#!/bin/bash
#PBS -l walltime=48:00:00,nodes=1:ppn=1

############
# Routines #
############
function exec_time {
	# Print time and message given as arg
	 echo "[$(date +'%T')] $1"
}
function generateJoinColumns {
	# Output the following string format (required by the join command): $1.$2,$1.$2+1,$1.$2+2,$1.n,...,$1.$3
	# Args: $1 (file - 1 our 2), $2 (start col), $3 (end col)
	# Example: keep cols 2-5 in file 1 : 1.2,1.3,1.4,1.5 (generateJoinColumns 1 2 5) 
	for ((i=$2; i<=$3;i++)) {
		echo "$1.$i"
	} | paste -s -d","
}

##############
# Parameters #
##############
echo $workdir
echo $annoDB
echo $hg
echo $chr
echo $BCFs
echo $clean
echo ${BCFDIR}
echo ${ver}
echo ${dnaPath}

if [[ -z $workdir || -z $annoDB || -z $hg || -z $chr || -z $BCFs || -z $clean || -z ${BCFDIR} || -z ${ver} || -z ${dnaPath} ]]; then
	echo -e "Missing variable(s):\n\tworkdir\n\tannoDB\n\thg\n\tchr\n\tBCFs\n\tclean\n\tBCFDIR\n\tBCFTOOLS_version\n\tDNASEQ variants tool path" && exit 1
fi

echo "Starting allelicExpression.V2.sh..."

#############################################
#
#    test which version of BCFTOOLS to use
#    version 0.2.0 index .csi
#    version 0.1.19 index .bci 
#
#############################################
if [[ "${ver}" == "0.1.19" ]]; then                  echo "Use BCFTOOLS V.0.1.19 ..."; BCFTOOLS="bcftools"; fi
if [[ "${ver}" == "0.2.0" && -n "${BCFDIR}" ]]; then echo "Use BCFTOOLS V.0.2.0 ...";  BCFTOOLS="${BCFDIR}/bcftools"; fi
if [[ "${ver}" == "0.2.0" && -z "${BCFDIR}" ]]; then echo "You want to use BCFTOOLS V.0.2 but var BCFDIR not available in environment"; exit 102; fi

cd $workdir || exit 2
hg="--buildver $hg"
annoLog="AnnoLog.txt"
args=`cat $BCFs | tr ":" " "`
if [[ -e $annoLog ]]; then rm $annoLog; fi

###################
# Processing ARGS #
###################
exec_time "Processing args..."
if [[ ${#args} -lt 1 ]]; then echo "You must provide at least one BCF file." && exit 3; fi
# For each file: store it as BCF, extract its name and prepare avinput file
for arg in $args; do
	if [[ ! -e $arg ]]; then echo "Error: $arg does not exist." && exit 4; fi
	bcfs[${#bcfs[@]}]=$arg	
	names[${#names[@]}]=`basename $arg .bcf | cut -f1 -d"_"`
	avinputs[${#avinputs[@]}]=`echo "$(basename $arg .bcf).avinput"`
done
# Check that, for unknown reason, arrays have differents lengths
if [[ ${#bcfs[@]} -ne ${#names[@]} || ${#bcfs[@]} -ne ${#avinputs[@]} ]]; then
	echo -e "Arrays do not have the same length:\n\tBCFs= ${bcfs[@]}\n\tNAMES= ${names[@]}\n\tAVINPUTS= ${avinputs[@]}" && exit 5
fi

exec_time "Converting BCFs into AVINPUT..."
nbNotEmptyAvi=0                         ##  set the indicator of the number of files with at least 1 variant
for ((i=0; i<${#bcfs[@]}; i++)); do
	vcfFile="${names[$i]}_${chr}.vcf"
	${BCFTOOLS} view ${bcfs[$i]} ${chr} | awk 'BEGIN {OFS="\t";}; {
		status=match($8,"DP4=[0-9]+,[0-9]+,[0-9]+,[0-9]+",matchVal);
		if (status) {
			# Split tag and values
			split(matchVal[0],TAG,"=");
			# Split values
			split(TAG[2],vals,",");
			$6=vals[1]","vals[2]","vals[3]","vals[4];
			print;
		}
		# Print header (start with #)
		else if (match($1,"^#")) { print; }
	}'> $vcfFile || exit 6
	# Some mutations are redundant because of bcftools so sort them by DP, delete redundant entries with lowest DP and sort them by location
	/results/tools/annovar/convert2annovar.pl --format vcf4 $vcfFile 2>> $annoLog | sort -k8,8nr | sort -u -k1,5 | sort -k1,1 -k2,3n > ${avinputs[$i]} || exit 7
        # Test whether at least 1 mutation has been found in the sample - then increment flag
        if [ -s ${avinputs[$i]} ]; then let "nbNotEmptyAvi=nbNotEmptyAvi+1"; fi 
  rm $vcfFile || exit 8
done
## test whether all Avi are Empty
if [ $nbNotEmptyAvi -eq 0 ]; then exec_time "All AVINPUT files are empty ..."; exit 101; fi

#exit 0

#CLucchesi changed 2014-04-08 ----> exec_time "Joining AVINPUTs..."
exec_time "Create UNION of all AVINPUTs (concatenate avinputs lines in a single file ..."
# Keep only the 5 first columns and remove redundant mutations: create union file
unionFile="Union_${chr}.avinput"
cat ${avinputs[@]} | cut -f 1,2,3,4,5 | sort -u > $unionFile || exit 9
#finalFile=`echo $(echo ${names[@]} | sed 's/ /_/g')_${chr}.txt`
finalFile="Union_samples_${chr}.txt"

###################
# Running Annovar #
###################
exec_time "Processing 1000G_ALL..."
/results/tools/annovar/annotate_variation.pl $hg --filter --dbtype 1000g2014oct_all $unionFile $annoDB &>> $annoLog || exit 10
exec_time "Processing 1000G_EUR..."
/results/tools/annovar/annotate_variation.pl $hg --filter --dbtype 1000g2014oct_eur $unionFile $annoDB &>> $annoLog || exit 11
exec_time "Processing 1000G_AMR..."
/results/tools/annovar/annotate_variation.pl $hg --filter --dbtype 1000g2014oct_amr $unionFile $annoDB &>> $annoLog || exit 12
exec_time "Processing 1000G_ASN..."
/results/tools/annovar/annotate_variation.pl $hg --filter --dbtype 1000g2012apr_asn $unionFile $annoDB &>> $annoLog || exit 13
exec_time "Processing 1000G_AFR..."
/results/tools/annovar/annotate_variation.pl $hg --filter --dbtype 1000g2014oct_afr $unionFile $annoDB &>> $annoLog || exit 14
cat $unionFile.hg19_ASN.sites.2012_04_dropped | awk '{print $3":"$4":"$5":"$6":"$7"\t"$2}' | sort -k1,1 > 1000G_ASN.txt
for i in ALL EUR AMR AFR; do
	cat $unionFile.hg19_$i.sites.2014_10_dropped | awk '{print $3":"$4":"$5":"$6":"$7"\t"$2}' | sort -k1,1 > 1000G_$i.txt
done
exec_time "Processing COSMIC..."
/results/tools/annovar/annotate_variation.pl $hg --filter --dbtype cosmic70 $unionFile $annoDB &>> $annoLog || exit 15
cat $unionFile.hg19_cosmic70_dropped | awk '{print $3":"$4":"$5":"$6":"$7"\t"$2}' | sort -k1,1 > COSMIC.txt
exec_time "Processing dbSNP..."
/results/tools/annovar/annotate_variation.pl $hg --filter --dbtype snp138 $unionFile $annoDB &>> $annoLog || exit 16
cat $unionFile.hg19_snp138_dropped | awk '{print $3":"$4":"$5":"$6":"$7"\t"$2}' | sort -k1,1 > SNP.txt
exec_time "Processing ClinVar..."

/results/tools/annovar/annotate_variation.pl $hg --filter --dbtype clinvar_20150330 $unionFile $annoDB &>> $annoLog || exit 17
cat $unionFile.hg19_clinvar_20150330_dropped | awk '{print $3":"$4":"$5":"$6":"$7"\t"$2}' | sort -k1,1 > CLINVAR.txt

exec_time "Processing Segmental duplications..."
/results/tools/annovar/annotate_variation.pl $hg --regionanno --dbtype genomicSuperDups $unionFile $annoDB &>> $annoLog || exit 18
cat $unionFile.hg19_genomicSuperDups | awk '{print $3":"$4":"$5":"$6":"$7"\t"$2}' | sort -k1,1 > SegDup.txt
exec_time "Processing DGV..."
# Do not show all results: only the first 3
/results/tools/annovar/annotate_variation.pl $hg --regionanno --dbtype dgvMerged $unionFile $annoDB &>> $annoLog || exit 19
cat $unionFile.hg19_dgvMerged | awk '{
		outS="";
		n=split($2,inS,",");
		if (n==1) 	{outS=inS[1];}
		else if (n==2)	{outS=inS[1]","inS[2];}
		else if (n==3)	{outS=inS[1]","inS[2]","inS[3];}
		else if (n>3)	{outS=inS[1]","inS[2]","inS[3]",...";}
		print $3":"$4":"$5":"$6":"$7"\t"outS;
	}' | sort -k1,1 > dgvMerged.txt
exec_time "Processing LJB2 (mutation consequence at protein level)..."
/results/tools/annovar/annotate_variation.pl $hg --filter --otherinfo --dbtype ljb26_all $unionFile $annoDB &>> $annoLog || exit 20 
cat $unionFile.hg19_ljb26_all_dropped | awk '{print $3":"$4":"$5":"$6":"$7"\t"$2}' | sort -k1,1 > LJB2.txt
exec_time "Processing gene annotation..."

#### JChiron CHANGE 2015-01-23
# to use HGVS format annotation for c. and p. : --hgvs parameter added
# to extended splice site to 5b around exon : --splicing_threshold 5

#/results/tools/annovar/annotate_variation.pl $hg --geneanno $unionFile $annoDB &>> $annoLog || exit 21
/results/tools/annovar/annotate_variation.pl $hg --geneanno --hgvs --splicing_threshold 5 $unionFile $annoDB &>> $annoLog || exit 21
cat $unionFile.variant_function | awk '{print $3":"$4":"$5":"$6":"$7"\t"$1"\t"$2}' | sort -k1,1 > Variant_function.txt
### BUG CORRECTION ###
#cat $unionFile.exonic_variant_function | awk '{print $5":"$6":"$7":"$8":"$9"\t"$2"\t"$3"\t"$4}' | sort -k1,1 > Exonic_variant_function.txt
python /results/tools/VARIANT_ANNOTATION_V5_2014_07_04/parse_exonic_variant_function.py $unionFile.exonic_variant_function `pwd` && sort -k1,1 Exonic_variant_function_temp.txt > Exonic_variant_function.txt
# At this point, all main information are stored in TXT files (above) in the following format:
#	CHR:START:END:REF:ALT	INFORMATION
# So, column 1 acts as a key to join columns in all TXT files

###################
# Merging columns #
###################
exec_time "Merging data..."
merging_opts="--check-order -a1 -e NA -j 1 -o"
join $merging_opts `generateJoinColumns 1 1 3`,`generateJoinColumns 2 2 4` Variant_function.txt Exonic_variant_function.txt | sed 's/ /\t/g' > tmp.txt
join $merging_opts `generateJoinColumns 1 1 6`,`generateJoinColumns 2 2 2` tmp.txt 1000G_ALL.txt | sed 's/ /\t/g' > tmp2.txt
join $merging_opts `generateJoinColumns 1 1 7`,`generateJoinColumns 2 2 2` tmp2.txt 1000G_EUR.txt | sed 's/ /\t/g' > tmp.txt
join $merging_opts `generateJoinColumns 1 1 8`,`generateJoinColumns 2 2 2` tmp.txt 1000G_AMR.txt | sed 's/ /\t/g' > tmp2.txt
join $merging_opts `generateJoinColumns 1 1 9`,`generateJoinColumns 2 2 2` tmp2.txt 1000G_ASN.txt | sed 's/ /\t/g' > tmp.txt
join $merging_opts `generateJoinColumns 1 1 10`,`generateJoinColumns 2 2 2` tmp.txt 1000G_AFR.txt | sed 's/ /\t/g' > tmp2.txt
join $merging_opts `generateJoinColumns 1 1 11`,`generateJoinColumns 2 2 2` tmp2.txt COSMIC.txt | sed 's/ /\t/g' > tmp.txt
join $merging_opts `generateJoinColumns 1 1 12`,`generateJoinColumns 2 2 2` tmp.txt SNP.txt | sed 's/ /\t/g' > tmp2.txt
join $merging_opts `generateJoinColumns 1 1 13`,`generateJoinColumns 2 2 2` tmp2.txt CLINVAR.txt | sed 's/ /\t/g' > tmp.txt
join $merging_opts `generateJoinColumns 1 1 14`,`generateJoinColumns 2 2 2` tmp.txt SegDup.txt | sed 's/ /\t/g' > tmp2.txt
join $merging_opts `generateJoinColumns 1 1 15`,`generateJoinColumns 2 2 2` tmp2.txt dgvMerged.txt | sed 's/ /\t/g' > tmp.txt
join $merging_opts `generateJoinColumns 1 1 16`,`generateJoinColumns 2 2 2` tmp.txt LJB2.txt | sed 's/ /\t/g' > tmp2.txt
# At this point, information for mutations are stored in a single file. Now, add DP4 information from modified avinputs given as inputs
# There are $index columns at this point
lastTMP="tmp2.txt"
otherTMP="tmp.txt"
index=`cat $lastTMP | awk '{print NF;}' | sort -urn | head -n1`
# For each sample, generate key by parsing avinput file and add the DP4 column into the ouput
for ((i=0; i<${#avinputs[@]}; i++)); do
	# Alternate input and ouput tmp file 
	if [[ $i%2 -eq 0 ]]; then tmpIN=$lastTMP; tmpOUT=$otherTMP; else tmpIN=$otherTMP; tmpOUT=$lastTMP; fi
	# Add DP4 value
	join $merging_opts `generateJoinColumns 1 1 $index`,`generateJoinColumns 2 2 2` $tmpIN \
		<(cat ${avinputs[$i]} | awk '{print $1":"$2":"$3":"$4":"$5"\t"$7}' | sort -k1,1) | sed 's/ /\t/g' > $tmpOUT
	let index=$index+1
done
cat $tmpOUT > mergedData_1.txt

###############################################
# Getting DP4 reference if DP4 mutation is NA #
###############################################
exec_time "Merging Alt with Ref..."
# $index has to be the index of the first sample
let index=$index-${#bcfs[@]}+1
cols="$index"
# Select DP4 columns for the cut command
for ((i=$index+1;i<=$index+${#bcfs[@]}-1;i++)); do
	cols="$cols,$i"
done
while read line; do
	nSample=0
	# For each DP4 value
	missingDP4="F"
	for DP4sample in `echo -e "$line" | cut -f $cols`; do
		# If DP4 is not set, then look into bcf
		if [[ $DP4sample == "NA" ]]; then
			missingDP4="T"
			# Get mutation loc 
			loc=`echo -e "$line" | cut -f2 -d":"`
			LOC=`echo -e "$line" | cut -f 1,2 -d":" | awk 'BEGIN {FS=":"};{print $1":"$2"-"$2}'`
			refBase=`echo -e "$line" | cut -f4 -d":"`
### WARNING !!!! WARNING !!!!
### CLucchesi CHANGE 2014-04-08 ---> add altBase variable
			altBase=`echo -e "$line" | cut -f5 -d":"`
			# Get val at this location using bcftools
			result=`${BCFTOOLS} view ${bcfs[$nSample]} $LOC | grep -Ev "^#"`
			# Get column number
### CLucchesi CHANGE 2014-04-08 ---> use regexp for FS
###			colN=`echo $result | awk 'BEGIN {FS=" "}; {print NF}'`
#			colN=`echo $result | awk 'BEGIN {FS="[ \t]+"}; {print NF}'`
			colN=`echo -e "${result}" | awk 'BEGIN {FS="[\t]"}; {print NF}'`
			# If colN is 0 (no hit), set DP4 at 0
			if [[ ${colN} == 0 ]]; then DP4="0,0,0,0"; fi
			# If colN is 10 (one hit), set DP4 at hit value only if it matches the reference
			if [[ ${colN} == 10 ]]; then 
#### CLucchesi CHANGE ----> 2014-04-29 ---> use regexp for FS
####					awk -v refBase=$refBase -v altBase=$altBase -v loc=$loc 'BEGIN {FS=" "; "\t";};{
####					awk -v refBase=$refBase -v altBase=$altBase -v loc=$loc 'BEGIN {FS="[ \t]+"; OFS="\t";};{
				DP4=`echo -e "$result" | awk -v refBase="$refBase" -v altBase="$altBase" -v loc=$loc 'BEGIN {FS="[\t]";OFS="\t"};{
						# If (hit ref is equals to ref OR ref is an insertion) AND alt is . and loc looks good, grab DP4
#### CLucchesi CHANGE ---> 2014-04_08 if (($4==substr(refBase,0,1) || substr(refBase,0,1)=="-" ) && $5=="." && $2==loc)
####  CHANGE ------------------------------------------> the position id reported even if ALT_BASE ($5) is not eq to "."; it can also be equal to altBase
                                                # If (hit ref is equals to ref OR ref is an insertion) AND loc looks good, grab DP4
 						if (($4==substr(refBase,0,1) || substr(refBase,0,1)=="-" ) && ($5=="." || $5==altBase) && $2==loc)
							{print $0;}
						else
							{print "DP4=0,0,0,0;";}
					}' | sed -r 's/.*DP4=([0-9]+,[0-9]+,[0-9]+,[0-9]+);.*/\1/g'`;
			# If colN is >10 (multiple hits), only get the DP4 when hit matches the reference
			fi
          if [[ ${colN} > 10 ]]; then 
            DP4=`echo -e "$result" | awk 'BEGIN {ORS="#"}; {print}' | awk -v refBase=$refBase -v colN=$colN -v loc=$loc '{
				DP4="0,0,0,0";
				nBatch=split($0,batch,"#");
				for (i=1;i<=nBatch-1;i++) {
					split(batch[i],res," ");
					if ((res[4]==substr(refBase,0,1) || substr(refBase,0,1)=="-" ) && res[5]=="." && res[2]==loc) {
						# Grab DP4 using a regex, then split it and modify DP4 variable.
						status=match(res[8],"DP4=[0-9]+,[0-9]+,[0-9]+,[0-9]+",matchVal);
						if (status) {
							split(matchVal[0],TAG,"=");
							split(TAG[2],vals,",");
							DP4=vals[1]","vals[2]","vals[3]","vals[4];
							# Break the loop because the good hit has been found and print its DP4
							break;
						}
					}
				}
				print DP4;
			 }'`; 
          fi
          let indexM=$index+$nSample
      # Assign DP4 value to the correct column (=sample)
          line=`echo -e "$line" | awk -v DP4=$DP4 'BEGIN {OFS="\t"}; {$'$indexM'=DP4; print;}'`
### CLucchesi ADD ---
#          if [ "${LOC}" == "chr17:1316961-1316961" ]; then
#                          echo -e "Report locus chr17:1316961-1316961 for Sample_number=${nSample}" >> TMP_LOCUS_REPORT.txt
#                          echo -e "BCF_data_at_locus=${result}"                                     >> TMP_LOCUS_REPORT.txt
#                          echo -e "NbOfColumnsOfBCFdata=$colN"                                      >> TMP_LOCUS_REPORT.txt
#                          echo -e "DP4=$DP4"                                                        >> TMP_LOCUS_REPORT.txt
#                          echo -e "Output_line=${line}"                                             >> TMP_LOCUS_REPORT.txt
#                          echo -e "\n"                                                              >> TMP_LOCUS_REPORT.txt
#          fi
         fi
       let nSample=${nSample}+1
       done
  echo -e "$line" | sed 's/ /\t/g'
done < mergedData_1.txt > mergedData_2.txt

##########################
# Reordering information #
##########################
exec_time "Reordering information..."
# The first column will be split into 5 so add 4 (5-1) to the index (number of columns)
# Index refers to the first sample column
let index=$index+4
# Set nSamples to the last column of samples so a loop could iterate on each sample from $index to $nSamples
let nSamples=$index+${#bcfs[@]}-1
# Generate output header 
header="CHROM START STOP REF ALT"
for ((i=0;i<${#names[@]};i++)); do
	header="$header ${names[$i]}_DP4_REF_FW ${names[$i]}_DP4_REF_BW ${names[$i]}_DP4_ALT_FW ${names[$i]}_DP4_ALT_BW"
	header="$header ${names[$i]}_DP4_TOT ${names[$i]}_DP4_ALT ${names[$i]}_DP4_ALT_RATIO ${names[$i]}_DP4_FWD_RATIO"
done
header="$header GENE UCSC_LINK QUICKGO_LINK GENE_REGION TYPE TRANSCRIPTS 1000G_ALL 1000G_EUR 1000G_AMR 1000G_ASN 1000G_AFR COSMIC dbSNP CLINVAR"
header="$header SEGDUP DGV SIFT_SCORE SIFT_INTERPRETATION POLYPHEN2_HDIV_SCORE POLYPHEN2_HDIV_INTERPRETATION POLYPHEN2_HVAR_SCORE"
header="$header POLYPHEN2_HVAR_INTERPRETATION LRT_SCORE LRT_INTERPRETATION MUTATIONTASTER_SCORE MUTATIONTASTER_INTERPRETATION"
header="$header MUTATIONASSESSOR_SCORE MUTATIONASSESSOR_INTERPRETATION FATHMM_SCORE FATHMM_INTERPRETATION GERP++_SCORE PHYLOP_SCORE SIPHY_SCORE"
echo $header | sed 's/ /\t/g' > mergedData_3.txt
# For each line in advanced file
while read line; do
	# Split CHR:START:STOP:REF:ALT
	line=`echo $line | sed 's/:/\t/1' | sed 's/:/\t/1' | sed 's/:/\t/1' | sed 's/:/\t/1'`
	# Use awk to modify output format. \x27 is ' (simple quote) char
	echo $line | awk -v indeX=$index -v nSamples=$nSamples '{
		# Split line
		split($0,res," ");
		###################
		# Output location #
		###################
		# Initialize out variable (output) and start to fill it with chr, start, stop, ref and alt
		out=res[1];
		for (i=2; i<=5; i++)
			out=out"\t"res[i];
		#############
		# Parse DP4 #
		#############
		# Then use indeX and nSamples variable to process DP4 samples, so for each DP4
		for (i=indeX; i<=nSamples; i++) {
			# Split DP4
			split(res[i],DP4,",");
			# Compute some metrics
			TOT=DP4[1]+DP4[2]+DP4[3]+DP4[4];
			TOT_ALT=DP4[3]+DP4[4];
			if (TOT!=0) {ALT_RATIO=TOT_ALT/TOT;} else {ALT_RATIO="NA";}
			TOT_FWD=DP4[1]+DP4[3];
			TOT_RVS=DP4[2]+DP4[4];
			if (TOT_FWD+TOT_RVS!=0) {STD_BIAIS=TOT_FWD/(TOT_FWD+TOT_RVS);} else {STD_BIAIS="NA";}
			# Add DP4 and useful metrics
			out=out"\t"DP4[1]"\t"DP4[2]"\t"DP4[3]"\t"DP4[4]"\t"TOT"\t"TOT_ALT"\t"ALT_RATIO"\t"STD_BIAIS;
		}
		#######################
		# General information #
		#######################
		# Add gene name with quotes (\x27)
		out=out"\t\x22"res[7]"\x22";
		# Add link to UCSC
		out=out"\thttp://genome.ucsc.edu/cgi-bin/hgTracks?org=Human&db=hg19&position="res[1]":"res[2]-2"-"res[3]+2;
		# Add link to QuickGO
		n=split(res[7],geneNameArray,",");
		if (n>1) {geneName=geneNameArray[1];}
		else {geneName=res[7];}
		out=out"\thttp://www.ebi.ac.uk/QuickGO/GSearch?q="geneName"#1=2";
		# Add gene region
		out=out"\t"res[6];
		# Modify mutation type to fit strandard
		if (res[8]=="stopgain") {res[8]="nonsense";}
		else if (res[8]=="nonsynonymous") {res[8]="missense";}
		else if (res[8]=="startgain") {res[8]="initiating_methionine";}
		# Delete gene name in transcript (redundant)
		gsub(res[7]":","",res[10]);
		# Add all other columns except DIV (col 9) and LJB (col indeX-1) which requires specific processing
		for (i=8; i<=indeX-2; i++) {
			if (i!=9)
				out=out"\t"res[i];
		}
		######################
		# Parse LBJ database #
		######################

		##!!!! CHANGED (JC & TB 11/06/15) : ljb updated with annovar from ljb2 to ljb26
		# output format changed => update parsing method to retrieve fields
		
 
		# Split LBJ information and store array size
		aSize=split(res[indeX-1],LJB,",");
		# If array is empty, then put "NAs"
		#if (aSize!=15) { #ljb2 output contains 15 fields
		if (aSize!=25) { #ljb26 output contains 25 fields
			res[indeX-1]="NA";
			for (i=2;i<=17;i++)
				res[indeX-1]=res[indeX-1]"\tNA";
		}
		# Else, then add information
		else {
			#for (i=1;i<=15;i++)
			for (i=1;i<=25;i++)
				if (LJB[i]==".") {LJB[i]="NA";}
			# 1 - SIFT
			LJBout[1]=LJB[1]
			if (LJB[1]!="NA") {
				if (LJB[1]<=0.05)	{LJBout[2]="Damaging";}
				else if (LJB[1]>0.05)	{LJBout[2]="Tolerated";}
			}
			else				{LJBout[2]="NA";}
			
			# 2 - Polyphen2-HDIV
			LJBout[3]=LJB[3]
			if (LJB[4]=="D")		{LJBout[4]="Probably_damaging";}
			else if (LJB[4]=="P")		{LJBout[4]="Possibly_damaging";}
			else if (LJB[4]=="B")		{LJBout[4]="Benign";}
			else				{LJBout[4]="NA";}
			
			# 3 - Polyphen2-HVAR
			LJBout[5]=LJB[5]
			if (LJB[6]=="D")		{LJBout[6]="Probably_damaging";}
			else if (LJB[6]=="P")		{LJBout[6]="Possibly_damaging";}
			else if (LJB[6]=="B")		{LJBout[6]="Benign";}
			else				{LJBout[6]="NA";}

			# 4 - LRT
			LJBout[7]=LJB[7]
			if (LJB[8]=="N")		{LJBout[8]="Neutral";}
			else if (LJB[8]=="D")		{LJBout[8]="Deleterious";}
			else if (LJB[8]=="U")		{LJBout[8]="Unknown";}
			else				{LJBout[8]="NA";}

			# 5 - MutationTaster
			LJBout[9]=LJB[9]
			if (LJB[10]=="A")		{LJBout[10]="Disease_causing_automatic";}
			else if (LJB[10]=="D")		{LJBout[10]="Disease_causing";}
			else if (LJB[10]=="P")		{LJBout[10]="Polymorphism";}
			else if (LJB[10]=="N")		{LJBout[10]="Polymorphism_automatic";}
			else				{LJBout[10]="NA";}
			
			# 6 - MutationAssessor
			LJBout[11]=LJB[11]
			if (LJB[12]=="L")		{LJBout[12]="Low";}
			else if (LJB[12]=="M")	{LJBout[12]="Medium";}
			else if (LJB[12]=="H")	{LJBout[12]="High";}
			else if (LJB[12]=="N")	{LJBout[12]="Neutral";}
			else				{LJBout[12]="NA";}			

			# 7 - Fathmm
			LJBout[13]=LJB[13]
			if (LJB[12]!="NA") {
				if (LJB[12]<=-1.5)	{LJBout[14]="Damaging";}
				else if (LJB[12]>-1.5)	{LJBout[14]="Tolerated";}
			}
			else				{LJBout[14]="NA";}

			# 8 - GERP++
			LJBout[15]=LJB[22]
			# 9 - PhyloP
			LJBout[16]=LJB[23]
			# 10 - Siphy
			LJBout[17]=LJB[25]
			
			res[indeX-1]=LJBout[1];
			for (i=2;i<=17;i++)
				res[indeX-1]=res[indeX-1]"\t"LJBout[i];
		}
		out=out"\t"res[indeX-1];
		print out;
	}'
done < mergedData_2.txt | sort -k1,1 -k2,3n >> mergedData_3.txt

exec_time "Computing statistics..."
R --vanilla --args $workdir/mergedData_3.txt $workdir/$finalFile < ${dnaPath}/allelicExpressionStats.R > R.log || exit 22

###################
# Cleaning folder #
###################
exec_time "Cleaning folder..."
if [[ $clean == "yes" ]]; then
	rm *_dropped *_filtered tmp.txt tmp2.txt 1000G_ALL.txt 1000G_EUR.txt 1000G_AMR.txt 1000G_ASN.txt 1000G_AFR.txt \
		Variant_function.txt Exonic_variant_function.txt COSMIC.txt SNP.txt LJB2.txt dgvMerged.txt SegDup.txt CLINVAR.txt \
		$unionFile.variant_function $unionFile.hg19_dgvMerged $unionFile.hg19_genomicSuperDups \
		$unionFile.exonic_variant_function ${avinputs[@]} $unionFile
	rm *.log mergedData_*.txt
fi
exec_time "Done."



